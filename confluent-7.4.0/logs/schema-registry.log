[2023-07-19 19:23:23,895] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-19 19:23:23,961] INFO Logging initialized @879ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-19 19:23:23,992] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-19 19:23:24,123] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-19 19:23:24,402] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:24,404] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:24,990] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:24,990] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:24,990] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:25,013] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,169] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-19 19:23:25,177] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-19 19:23:25,197] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,199] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,296] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 19:23:25,340] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 19:23:25,341] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 19:23:25,343] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 19:23:25,431] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,461] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,471] INFO Creating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-19 19:23:25,472] WARN Creating the topic _schema_encoders using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-19 19:23:25,520] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-19 19:23:25,521] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-19 19:23:25,521] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-19 19:23:25,527] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-19 19:23:25,528] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-19 19:23:25,529] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 19:23:25,529] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-19 19:23:25,544] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,546] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,555] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-5ba76b79-aaba-4cd8-a3c4-3dd477a5c0df (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,556] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,556] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,559] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=1, memberId='sr-1-5ba76b79-aaba-4cd8-a3c4-3dd477a5c0df', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,571] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=1, memberId='sr-1-5ba76b79-aaba-4cd8-a3c4-3dd477a5c0df', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 19:23:25,573] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-5ba76b79-aaba-4cd8-a3c4-3dd477a5c0df', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-19 19:23:25,593] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:25,594] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 19:23:26,035] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-19 19:23:26,035] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-19 19:23:26,075] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-19 19:23:26,164] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-19 19:23:26,198] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-19 19:23:26,199] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-19 19:23:26,200] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2023-07-19 19:23:26,577] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-19 19:23:26,760] INFO Started o.e.j.s.ServletContextHandler@4eb45fec{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-19 19:23:26,772] INFO Started o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-19 19:23:26,788] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-19 19:23:26,788] INFO Started @3709ms (org.eclipse.jetty.server.Server)
[2023-07-19 19:23:26,789] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-19 19:23:26,790] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-19 21:35:00,025] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-19 21:42:20,890] INFO KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[2023-07-19 21:42:21,180] ERROR Could not parse Avro schema (io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider)
org.apache.avro.SchemaParseException: Illegal character in: kafka-students
	at org.apache.avro.Schema.validateName(Schema.java:1571)
	at org.apache.avro.Schema.access$400(Schema.java:92)
	at org.apache.avro.Schema$Name.<init>(Schema.java:704)
	at org.apache.avro.Schema.parse(Schema.java:1656)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1433)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1421)
	at io.confluent.kafka.schemaregistry.avro.AvroSchema.<init>(AvroSchema.java:120)
	at io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider.parseSchemaOrElseThrow(AvroSchemaProvider.java:54)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:114)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:123)
	at io.confluent.kafka.formatter.SchemaMessageReader.parseSchema(SchemaMessageReader.java:264)
	at io.confluent.kafka.formatter.SchemaMessageReader.getSchema(SchemaMessageReader.java:278)
	at io.confluent.kafka.formatter.SchemaMessageReader.init(SchemaMessageReader.java:198)
	at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:42)
	at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
[2023-07-19 21:44:42,830] INFO KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[2023-07-19 21:44:43,046] ERROR Could not parse Avro schema (io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider)
org.apache.avro.SchemaParseException: Illegal character in: kafka-students
	at org.apache.avro.Schema.validateName(Schema.java:1571)
	at org.apache.avro.Schema.access$400(Schema.java:92)
	at org.apache.avro.Schema$Name.<init>(Schema.java:704)
	at org.apache.avro.Schema.parse(Schema.java:1656)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1433)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1421)
	at io.confluent.kafka.schemaregistry.avro.AvroSchema.<init>(AvroSchema.java:120)
	at io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider.parseSchemaOrElseThrow(AvroSchemaProvider.java:54)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:114)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:123)
	at io.confluent.kafka.formatter.SchemaMessageReader.parseSchema(SchemaMessageReader.java:264)
	at io.confluent.kafka.formatter.SchemaMessageReader.getSchema(SchemaMessageReader.java:278)
	at io.confluent.kafka.formatter.SchemaMessageReader.init(SchemaMessageReader.java:198)
	at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:42)
	at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
[2023-07-19 21:47:14,719] INFO KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[2023-07-19 21:47:14,914] ERROR Could not parse Avro schema (io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider)
org.apache.avro.SchemaParseException: Illegal character in: kafka-students
	at org.apache.avro.Schema.validateName(Schema.java:1571)
	at org.apache.avro.Schema.access$400(Schema.java:92)
	at org.apache.avro.Schema$Name.<init>(Schema.java:704)
	at org.apache.avro.Schema.parse(Schema.java:1656)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1433)
	at org.apache.avro.Schema$Parser.parse(Schema.java:1421)
	at io.confluent.kafka.schemaregistry.avro.AvroSchema.<init>(AvroSchema.java:120)
	at io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider.parseSchemaOrElseThrow(AvroSchemaProvider.java:54)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:114)
	at io.confluent.kafka.schemaregistry.SchemaProvider.parseSchema(SchemaProvider.java:123)
	at io.confluent.kafka.formatter.SchemaMessageReader.parseSchema(SchemaMessageReader.java:264)
	at io.confluent.kafka.formatter.SchemaMessageReader.getSchema(SchemaMessageReader.java:278)
	at io.confluent.kafka.formatter.SchemaMessageReader.init(SchemaMessageReader.java:198)
	at kafka.tools.ConsoleProducer$.main(ConsoleProducer.scala:42)
	at kafka.tools.ConsoleProducer.main(ConsoleProducer.scala)
[2023-07-19 21:48:19,232] INFO KafkaAvroSerializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.remove.java.properties = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroSerializerConfig)
[2023-07-19 21:48:33,719] INFO Registering new schema: subject test-value, version null, id null, type null, schema size 221 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-19 21:48:33,785] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:48:33,785] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:48:33,817] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:48:33,837] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:48:33,886] INFO 127.0.0.1 - - [19/Jul/2023:14:48:33 +0000] "POST /subjects/test-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 447 (io.confluent.rest-utils.requests)
[2023-07-19 21:48:34,981] INFO 127.0.0.1 - - [19/Jul/2023:14:48:34 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=test-value HTTP/1.1" 200 284 "-" "Java/11.0.19" 18 (io.confluent.rest-utils.requests)
[2023-07-19 21:48:34,982] INFO 127.0.0.1 - - [19/Jul/2023:14:48:34 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=test-value HTTP/1.1" 200 284 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-19 21:48:35,267] INFO 127.0.0.1 - - [19/Jul/2023:14:48:35 +0000] "POST /subjects/test-value?normalize=false&deleted=true HTTP/1.1" 200 326 "-" "Java/11.0.19" 33 (io.confluent.rest-utils.requests)
[2023-07-19 21:52:39,274] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-19 21:52:39,276] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-19 21:52:39,284] INFO Stopped o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-19 21:52:39,306] INFO Stopped o.e.j.s.ServletContextHandler@4eb45fec{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-19 21:52:39,313] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-19 21:52:39,315] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 21:52:39,317] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 21:52:39,317] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 21:52:39,324] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-19 21:52:39,328] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:52:39,328] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-19 21:52:39,329] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-19 21:52:39,330] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-19 21:52:39,330] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-19 21:52:39,333] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-19 21:52:39,336] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-19 21:52:39,337] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-5ba76b79-aaba-4cd8-a3c4-3dd477a5c0df sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 21:52:39,340] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 21:52:39,340] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-19 21:52:39,340] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:26:59,254] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-20 17:26:59,326] INFO Logging initialized @1097ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-20 17:26:59,364] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-20 17:26:59,522] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-20 17:26:59,906] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:26:59,907] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:27:00,801] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:27:00,802] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:27:00,802] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:27:00,839] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,062] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-20 17:27:01,074] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-20 17:27:01,112] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,117] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,304] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:27:01,412] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:27:01,413] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:27:01,417] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:27:01,606] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,692] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,710] INFO Creating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:27:01,714] WARN Creating the topic _schema_encoders using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-20 17:27:01,799] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:27:01,801] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-20 17:27:01,801] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 17:27:01,810] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:27:01,814] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:27:01,814] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:27:01,814] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:27:01,841] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,843] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,860] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-021cd8e8-6d30-4fb3-8358-57ebb1b9e462 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,861] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,861] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,869] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=1, memberId='sr-1-021cd8e8-6d30-4fb3-8358-57ebb1b9e462', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,889] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=1, memberId='sr-1-021cd8e8-6d30-4fb3-8358-57ebb1b9e462', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:27:01,894] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-021cd8e8-6d30-4fb3-8358-57ebb1b9e462', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-20 17:27:01,925] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:01,927] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:27:02,322] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:27:02,322] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:27:02,400] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-20 17:27:02,572] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-20 17:27:02,628] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-20 17:27:02,628] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-20 17:27:02,631] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2023-07-20 17:27:03,279] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-20 17:27:03,680] INFO Started o.e.j.s.ServletContextHandler@4eb45fec{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:27:03,704] INFO Started o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:27:03,723] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 17:27:03,724] INFO Started @5497ms (org.eclipse.jetty.server.Server)
[2023-07-20 17:27:03,725] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 17:27:03,725] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 17:46:43,246] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 17:46:43,248] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-20 17:46:43,255] INFO Stopped o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:46:43,286] INFO Stopped o.e.j.s.ServletContextHandler@4eb45fec{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:46:43,292] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:43,294] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:43,295] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:43,295] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:43,297] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:43,299] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:43,300] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:43,300] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-20 17:46:43,301] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:46:43,301] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:46:43,307] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 17:46:43,309] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:46:43,310] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-021cd8e8-6d30-4fb3-8358-57ebb1b9e462 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:43,312] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:43,312] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:43,312] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:48,551] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = localhost:2181
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-20 17:46:48,598] INFO Logging initialized @531ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-20 17:46:48,619] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-20 17:46:48,698] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-20 17:46:48,920] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:48,921] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:49,338] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:49,339] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:49,339] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:49,357] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,470] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-20 17:46:49,475] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-20 17:46:49,493] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,498] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,563] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:49,603] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:49,603] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:49,605] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:46:49,685] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,698] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,708] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:46:49,709] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-20 17:46:49,732] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:46:49,733] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-20 17:46:49,733] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 17:46:49,739] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:46:49,740] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:46:49,740] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:46:49,740] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:46:49,754] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,756] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,764] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-e7b4aaa2-8122-484d-8c62-f2de455ac2b9 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,764] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,764] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,766] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=3, memberId='sr-1-e7b4aaa2-8122-484d-8c62-f2de455ac2b9', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,775] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=3, memberId='sr-1-e7b4aaa2-8122-484d-8c62-f2de455ac2b9', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:46:49,780] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-e7b4aaa2-8122-484d-8c62-f2de455ac2b9', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-20 17:46:49,793] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:49,795] INFO Reached offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:46:50,244] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:46:50,244] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:46:50,279] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-20 17:46:50,374] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-20 17:46:50,411] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-20 17:46:50,412] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-20 17:46:50,413] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-20 17:46:50,787] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-20 17:46:50,976] INFO Started o.e.j.s.ServletContextHandler@5b84f14{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:46:50,990] INFO Started o.e.j.s.ServletContextHandler@367d2816{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:46:51,003] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 17:46:51,004] INFO Started @2939ms (org.eclipse.jetty.server.Server)
[2023-07-20 17:46:51,005] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 17:46:51,005] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 17:50:11,805] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 17:50:11,805] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-20 17:50:11,807] INFO Stopped o.e.j.s.ServletContextHandler@367d2816{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:50:11,822] INFO Stopped o.e.j.s.ServletContextHandler@5b84f14{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:50:11,824] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:11,825] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:11,825] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:11,825] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:11,827] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:11,829] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:11,829] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:11,829] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-20 17:50:11,830] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:50:11,830] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:50:11,832] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 17:50:11,833] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:50:11,834] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-e7b4aaa2-8122-484d-8c62-f2de455ac2b9 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:11,835] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:11,835] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:11,835] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:20,803] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-20 17:50:20,832] INFO Logging initialized @460ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-20 17:50:20,848] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-20 17:50:20,916] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-20 17:50:21,074] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,075] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,462] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,463] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,463] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,479] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,587] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-20 17:50:21,591] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-20 17:50:21,607] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,612] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,654] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:21,688] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:21,689] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:21,690] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 17:50:21,759] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,770] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,779] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:50:21,780] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-20 17:50:21,797] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:50:21,798] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-20 17:50:21,798] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 17:50:21,803] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:50:21,804] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:50:21,804] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 17:50:21,804] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-20 17:50:21,817] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,819] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,827] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-63d7f09e-a81d-4a4a-9a52-129b377c91bd (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,828] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,828] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,831] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=5, memberId='sr-1-63d7f09e-a81d-4a4a-9a52-129b377c91bd', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,840] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=5, memberId='sr-1-63d7f09e-a81d-4a4a-9a52-129b377c91bd', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 17:50:21,842] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-63d7f09e-a81d-4a4a-9a52-129b377c91bd', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-20 17:50:21,856] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:21,857] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 17:50:22,309] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-20 17:50:22,310] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-20 17:50:22,350] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-20 17:50:22,438] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-20 17:50:22,475] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-20 17:50:22,475] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-20 17:50:22,477] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-20 17:50:22,855] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-20 17:50:23,032] INFO Started o.e.j.s.ServletContextHandler@5b84f14{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:50:23,041] INFO Started o.e.j.s.ServletContextHandler@367d2816{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 17:50:23,054] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 17:50:23,055] INFO Started @2683ms (org.eclipse.jetty.server.Server)
[2023-07-20 17:50:23,056] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 17:50:23,056] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-20 20:42:07,611] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-20 20:42:07,626] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-20 20:42:07,662] INFO Stopped o.e.j.s.ServletContextHandler@367d2816{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 20:42:07,777] INFO Stopped o.e.j.s.ServletContextHandler@5b84f14{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-20 20:42:07,794] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-20 20:42:07,803] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 20:42:07,807] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 20:42:07,807] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 20:42:07,835] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-20 20:42:07,845] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 20:42:07,846] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-20 20:42:07,847] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-20 20:42:07,850] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-20 20:42:07,860] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-20 20:42:07,873] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-20 20:42:07,888] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-20 20:42:07,891] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-63d7f09e-a81d-4a4a-9a52-129b377c91bd sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 20:42:07,898] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 20:42:07,900] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-20 20:42:07,901] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:41,019] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 14:50:41,070] INFO Logging initialized @787ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 14:50:41,090] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 14:50:41,203] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 14:50:41,492] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:41,498] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:42,078] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:42,078] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:42,078] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:42,118] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,291] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 14:50:42,303] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 14:50:42,328] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,329] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,434] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 14:50:42,488] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 14:50:42,489] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 14:50:42,490] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 14:50:42,569] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,606] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,616] INFO Creating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 14:50:42,617] WARN Creating the topic _schema_encoders using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 14:50:42,665] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 14:50:42,666] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 14:50:42,666] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 14:50:42,671] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 14:50:42,673] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 14:50:42,673] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 14:50:42,673] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 14:50:42,693] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,695] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,705] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-6fa966ab-6e98-4e7a-83e5-3df96b32b726 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,705] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,705] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,709] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=1, memberId='sr-1-6fa966ab-6e98-4e7a-83e5-3df96b32b726', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,722] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=1, memberId='sr-1-6fa966ab-6e98-4e7a-83e5-3df96b32b726', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 14:50:42,725] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-6fa966ab-6e98-4e7a-83e5-3df96b32b726', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 14:50:42,748] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:42,749] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:50:43,180] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 14:50:43,180] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 14:50:43,230] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 14:50:43,369] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 14:50:43,407] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 14:50:43,408] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 14:50:43,409] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-21 14:50:43,836] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 14:50:44,081] INFO Started o.e.j.s.ServletContextHandler@3bd3d05e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 14:50:44,095] INFO Started o.e.j.s.ServletContextHandler@211febf3{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 14:50:44,112] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 14:50:44,113] INFO Started @3832ms (org.eclipse.jetty.server.Server)
[2023-07-21 14:50:44,114] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 14:50:44,114] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 14:51:02,074] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 288 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 14:51:02,135] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:51:02,135] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:51:02,151] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:51:02,179] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 14:51:02,204] INFO 127.0.0.1 - - [21/Jul/2023:07:51:01 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 256 (io.confluent.rest-utils.requests)
[2023-07-21 14:54:15,838] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 14:57:27,309] INFO 127.0.0.1 - - [21/Jul/2023:07:57:27 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 71 (io.confluent.rest-utils.requests)
[2023-07-21 14:58:12,333] INFO 127.0.0.1 - - [21/Jul/2023:07:58:12 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 15:01:55,673] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC[F-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:150)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 15:01:55,680] INFO 127.0.0.1 - - [21/Jul/2023:08:01:55 +0000] "GET /subjects/BTC%5BF-value/versions/latest HTTP/1.1" 404 65 "-" "Java/11.0.19" 23 (io.confluent.rest-utils.requests)
[2023-07-21 15:01:57,507] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC[F-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:150)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 15:01:57,510] INFO 127.0.0.1 - - [21/Jul/2023:08:01:57 +0000] "GET /subjects/BTC%5BF-value/versions/latest HTTP/1.1" 404 65 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 15:02:13,661] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:150)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 15:02:13,663] INFO 127.0.0.1 - - [21/Jul/2023:08:02:13 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 404 63 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 15:06:54,444] INFO 127.0.0.1 - - [21/Jul/2023:08:06:54 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-21 15:07:39,464] INFO 127.0.0.1 - - [21/Jul/2023:08:07:39 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 15:07:44,165] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:07:44,170] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:07:44,170] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:07:44,186] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 64 more
[2023-07-21 15:07:44,190] INFO 127.0.0.1 - - [21/Jul/2023:08:07:44 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 29 (io.confluent.rest-utils.requests)
[2023-07-21 15:10:32,364] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 15:11:11,649] INFO 127.0.0.1 - - [21/Jul/2023:08:11:11 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 11 (io.confluent.rest-utils.requests)
[2023-07-21 15:15:38,221] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:15:38,228] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:15:38,228] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:15:38,232] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 59 more
[2023-07-21 15:15:38,236] INFO 127.0.0.1 - - [21/Jul/2023:08:15:38 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 19 (io.confluent.rest-utils.requests)
[2023-07-21 15:21:09,358] INFO 127.0.0.1 - - [21/Jul/2023:08:21:09 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 15:21:12,743] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:21:12,744] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:21:12,744] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:21:12,745] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 64 more
[2023-07-21 15:21:12,747] INFO 127.0.0.1 - - [21/Jul/2023:08:21:12 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-21 15:22:13,644] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:22:13,644] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-21 15:22:13,647] INFO Stopped o.e.j.s.ServletContextHandler@211febf3{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:22:13,659] INFO Stopped o.e.j.s.ServletContextHandler@3bd3d05e{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:22:13,661] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:13,662] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:13,663] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:13,663] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:13,666] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:13,668] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:13,668] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:13,668] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-21 15:22:13,669] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:22:13,669] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:22:13,671] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:22:13,672] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:22:13,673] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-6fa966ab-6e98-4e7a-83e5-3df96b32b726 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:13,674] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:13,674] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:13,674] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:15,693] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 15:22:15,731] INFO Logging initialized @512ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 15:22:15,752] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 15:22:15,842] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 15:22:16,065] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:16,066] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:16,519] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:16,520] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:16,520] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:16,544] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:16,693] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 15:22:16,701] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 15:22:16,718] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:16,724] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:16,795] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:16,842] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:16,843] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:16,844] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:22:16,917] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:16,977] INFO Reached offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:16,985] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:22:16,987] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 15:22:17,003] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:22:17,004] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 15:22:17,004] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:22:17,010] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:22:17,011] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:22:17,011] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:22:17,011] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:22:17,026] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,028] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,035] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-6cfd1caf-7e96-4567-b171-9ed70a3d6ec1 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,035] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,035] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,038] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=3, memberId='sr-1-6cfd1caf-7e96-4567-b171-9ed70a3d6ec1', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,047] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=3, memberId='sr-1-6cfd1caf-7e96-4567-b171-9ed70a3d6ec1', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:22:17,048] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-6cfd1caf-7e96-4567-b171-9ed70a3d6ec1', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 15:22:17,061] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:17,063] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:22:17,517] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:22:17,517] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:22:17,560] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 15:22:17,678] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 15:22:17,712] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 15:22:17,713] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 15:22:17,714] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2023-07-21 15:22:18,159] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 15:22:18,425] INFO Started o.e.j.s.ServletContextHandler@68fe48d7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:22:18,435] INFO Started o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:22:18,447] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:22:18,448] INFO Started @3231ms (org.eclipse.jetty.server.Server)
[2023-07-21 15:22:18,449] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:22:18,449] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:23:08,417] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:23:08,472] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:23:08,472] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:23:08,491] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 59 more
[2023-07-21 15:23:08,522] INFO 127.0.0.1 - - [21/Jul/2023:08:23:08 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 234 (io.confluent.rest-utils.requests)
[2023-07-21 15:23:32,926] INFO 127.0.0.1 - - [21/Jul/2023:08:23:32 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 70 (io.confluent.rest-utils.requests)
[2023-07-21 15:23:37,557] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:23:37,558] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:23:37,558] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:23:37,560] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 64 more
[2023-07-21 15:23:37,564] INFO 127.0.0.1 - - [21/Jul/2023:08:23:37 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 10 (io.confluent.rest-utils.requests)
[2023-07-21 15:26:28,149] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:26:28,150] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:26:28,151] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:26:28,152] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestIncompatibleSchemaException: Schema being registered is incompatible with an earlier schema for subject "BTC_Avro-value", details: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.incompatibleSchemaException(Errors.java:134)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:424)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.IncompatibleSchemaException: [{errorType:'MISSING_UNION_BRANCH', description:'The new schema is missing a type inside a union field at path '/fields/0/type/1' in the old schema', additionalInfo:'reader union lacking writer type: INT'}, {oldSchemaVersion: 1}, {oldSchema: '{"type":"record","name":"KsqlDataSourceSchema","namespace":"io.confluent.ksql.avro_schemas","fields":[{"name":"PRICE","type":["null","int"],"default":null},{"name":"UPDATED_AT","type":["null","string"],"default":null}],"connect.name":"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema"}'}, {compatibility: 'BACKWARD'}]
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.register(KafkaSchemaRegistry.java:657)
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:762)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 59 more
[2023-07-21 15:26:28,157] INFO 127.0.0.1 - - [21/Jul/2023:08:26:28 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 409 740 "-" "Java/11.0.19" 14 (io.confluent.rest-utils.requests)
[2023-07-21 15:30:06,537] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:06,537] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:06,544] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:06,548] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:06,552] INFO 127.0.0.1 - - [21/Jul/2023:08:30:06 +0000] "PUT /config HTTP/1.1" 200 24 "-" "curl/7.81.0" 23 (io.confluent.rest-utils.requests)
[2023-07-21 15:30:11,589] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:11,589] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:11,590] INFO Wait to catch up until the offset at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:11,592] INFO Reached offset at 6 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:11,593] INFO 127.0.0.1 - - [21/Jul/2023:08:30:11 +0000] "PUT /config HTTP/1.1" 200 24 "-" "curl/7.81.0" 6 (io.confluent.rest-utils.requests)
[2023-07-21 15:30:23,549] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:30:23,550] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-21 15:30:23,551] INFO Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:30:23,562] INFO Stopped o.e.j.s.ServletContextHandler@68fe48d7{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:30:23,564] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:23,565] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:23,565] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:23,565] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:23,567] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:23,569] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:23,569] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:23,569] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-21 15:30:23,570] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:30:23,570] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:30:23,572] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:30:23,574] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:30:23,575] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-6cfd1caf-7e96-4567-b171-9ed70a3d6ec1 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:23,577] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:23,577] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:23,577] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:25,477] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 15:30:25,510] INFO Logging initialized @487ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 15:30:25,528] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 15:30:25,609] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 15:30:25,790] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:25,791] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:26,206] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:26,206] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:26,206] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:26,223] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,332] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 15:30:26,337] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 15:30:26,358] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,365] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,420] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:26,469] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:26,470] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:26,471] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:30:26,575] INFO Wait to catch up until the offset at 7 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,667] INFO Reached offset at 7 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,677] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:30:26,678] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 15:30:26,699] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:30:26,700] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 15:30:26,700] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:30:26,708] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:30:26,711] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:30:26,711] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:30:26,711] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:30:26,729] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,731] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,738] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-eeb9a581-d39e-4adf-92ad-eb3308d9d07b (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,738] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,738] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,740] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=5, memberId='sr-1-eeb9a581-d39e-4adf-92ad-eb3308d9d07b', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,746] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=5, memberId='sr-1-eeb9a581-d39e-4adf-92ad-eb3308d9d07b', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:30:26,748] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-eeb9a581-d39e-4adf-92ad-eb3308d9d07b', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 15:30:26,762] INFO Wait to catch up until the offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:26,763] INFO Reached offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:27,217] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:30:27,217] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:30:27,250] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 15:30:27,340] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 15:30:27,376] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 15:30:27,376] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 15:30:27,377] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
[2023-07-21 15:30:27,737] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 15:30:27,934] INFO Started o.e.j.s.ServletContextHandler@68fe48d7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:30:27,948] INFO Started o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:30:27,967] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:30:27,968] INFO Started @2947ms (org.eclipse.jetty.server.Server)
[2023-07-21 15:30:27,969] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:30:27,969] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:30:43,853] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:30:43,911] INFO Wait to catch up until the offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:43,912] INFO Reached offset at 8 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:43,930] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:43,932] INFO Reached offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:30:43,965] INFO 127.0.0.1 - - [21/Jul/2023:08:30:43 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 288 (io.confluent.rest-utils.requests)
[2023-07-21 15:30:54,028] INFO 127.0.0.1 - - [21/Jul/2023:08:30:53 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 78 (io.confluent.rest-utils.requests)
[2023-07-21 15:31:39,069] INFO 127.0.0.1 - - [21/Jul/2023:08:31:39 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 15:31:48,086] INFO 127.0.0.1 - - [21/Jul/2023:08:31:48 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 15:35:59,703] INFO Wait to catch up until the offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:35:59,703] INFO Reached offset at 9 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:35:59,707] INFO Wait to catch up until the offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:35:59,709] INFO Reached offset at 10 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:35:59,712] INFO 127.0.0.1 - - [21/Jul/2023:08:35:59 +0000] "PUT /config HTTP/1.1" 200 28 "-" "curl/7.81.0" 17 (io.confluent.rest-utils.requests)
[2023-07-21 15:36:07,104] INFO 127.0.0.1 - - [21/Jul/2023:08:36:07 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 15:36:29,753] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:36:29,760] INFO 127.0.0.1 - - [21/Jul/2023:08:36:29 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 10 (io.confluent.rest-utils.requests)
[2023-07-21 15:36:52,127] INFO 127.0.0.1 - - [21/Jul/2023:08:36:52 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 15:37:03,834] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:37:03,834] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-21 15:37:03,835] INFO Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:37:03,845] INFO Stopped o.e.j.s.ServletContextHandler@68fe48d7{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:37:03,847] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:03,848] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:03,848] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:03,848] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:03,850] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:03,852] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:03,852] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:03,852] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-21 15:37:03,853] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:37:03,853] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:37:03,855] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:37:03,857] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:37:03,858] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-eeb9a581-d39e-4adf-92ad-eb3308d9d07b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:03,859] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:03,859] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:03,859] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:05,991] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 15:37:06,035] INFO Logging initialized @509ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 15:37:06,053] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 15:37:06,132] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 15:37:06,311] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:06,312] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:06,800] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:06,800] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:06,800] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:06,819] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:06,932] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 15:37:06,937] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 15:37:06,956] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:06,962] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:07,011] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:07,048] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:07,049] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:07,050] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:37:07,157] INFO Wait to catch up until the offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:07,249] INFO Reached offset at 11 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:07,258] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:37:07,260] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 15:37:07,280] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:37:07,281] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 15:37:07,281] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:37:07,286] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:37:07,288] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:37:07,288] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:37:07,288] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:37:07,305] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,306] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,312] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-46cc0135-77d8-4135-ba5d-5eb58a4820e5 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,313] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,313] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,315] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=7, memberId='sr-1-46cc0135-77d8-4135-ba5d-5eb58a4820e5', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,322] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=7, memberId='sr-1-46cc0135-77d8-4135-ba5d-5eb58a4820e5', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:37:07,324] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-46cc0135-77d8-4135-ba5d-5eb58a4820e5', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 15:37:07,336] INFO Wait to catch up until the offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:07,337] INFO Reached offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:37:07,793] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:37:07,793] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:37:07,839] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 15:37:07,934] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 15:37:07,979] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 15:37:07,979] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 15:37:07,981] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-21 15:37:08,345] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 15:37:08,522] INFO Started o.e.j.s.ServletContextHandler@68fe48d7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:37:08,532] INFO Started o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:37:08,544] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:37:08,545] INFO Started @3020ms (org.eclipse.jetty.server.Server)
[2023-07-21 15:37:08,546] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:37:08,546] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:37:10,335] INFO 127.0.0.1 - - [21/Jul/2023:08:37:10 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 163 (io.confluent.rest-utils.requests)
[2023-07-21 15:38:18,957] INFO 127.0.0.1 - - [21/Jul/2023:08:38:18 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 15:38:27,060] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 15:38:27,101] INFO 127.0.0.1 - - [21/Jul/2023:08:38:27 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 83 (io.confluent.rest-utils.requests)
[2023-07-21 15:39:04,025] INFO 127.0.0.1 - - [21/Jul/2023:08:39:04 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 15:39:07,039] INFO 127.0.0.1 - - [21/Jul/2023:08:39:07 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 15:43:18,790] INFO 127.0.0.1 - - [21/Jul/2023:08:43:18 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-21 15:57:16,560] INFO Wait to catch up until the offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:57:16,560] INFO Reached offset at 12 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:57:16,566] INFO Wait to catch up until the offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:57:16,568] INFO Reached offset at 13 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:57:16,571] INFO 127.0.0.1 - - [21/Jul/2023:08:57:16 +0000] "PUT /config HTTP/1.1" 200 24 "-" "curl/7.81.0" 20 (io.confluent.rest-utils.requests)
[2023-07-21 15:59:46,808] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:59:46,809] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-21 15:59:46,811] INFO Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:59:46,821] INFO Stopped o.e.j.s.ServletContextHandler@68fe48d7{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:59:46,823] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:46,824] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:46,824] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:46,824] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:46,826] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:46,828] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:46,828] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:46,828] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-21 15:59:46,829] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:59:46,829] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:59:46,831] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:59:46,833] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:59:46,834] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-46cc0135-77d8-4135-ba5d-5eb58a4820e5 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:46,836] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:46,836] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:46,836] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:48,894] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 15:59:48,941] INFO Logging initialized @502ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 15:59:48,962] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 15:59:49,081] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 15:59:49,303] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:49,304] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:49,803] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:49,804] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:49,804] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:49,842] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:49,981] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 15:59:49,985] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 15:59:50,000] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,005] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,047] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:50,083] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:50,084] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:50,085] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 15:59:50,158] INFO Wait to catch up until the offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,248] INFO Reached offset at 14 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,258] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:59:50,260] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 15:59:50,283] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:59:50,284] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 15:59:50,285] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 15:59:50,292] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:59:50,294] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:59:50,295] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 15:59:50,295] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 15:59:50,316] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,318] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,326] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,326] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,327] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,329] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=9, memberId='sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,337] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=9, memberId='sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 15:59:50,339] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 15:59:50,358] INFO Wait to catch up until the offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,360] INFO Reached offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 15:59:50,802] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 15:59:50,803] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 15:59:50,837] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 15:59:50,929] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 15:59:50,965] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 15:59:50,965] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 15:59:50,967] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-21 15:59:51,379] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 15:59:51,610] INFO Started o.e.j.s.ServletContextHandler@68fe48d7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:59:51,627] INFO Started o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 15:59:51,651] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 15:59:51,652] INFO Started @3214ms (org.eclipse.jetty.server.Server)
[2023-07-21 15:59:51,653] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 15:59:51,653] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 16:00:34,114] INFO 127.0.0.1 - - [21/Jul/2023:09:00:33 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 227 (io.confluent.rest-utils.requests)
[2023-07-21 16:00:35,431] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 16:00:35,480] INFO 127.0.0.1 - - [21/Jul/2023:09:00:35 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 89 (io.confluent.rest-utils.requests)
[2023-07-21 16:01:19,160] INFO 127.0.0.1 - - [21/Jul/2023:09:01:19 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 16:06:41,927] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC_Avro' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.listVersions(SubjectVersionsResource.java:303)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 16:06:41,932] INFO 127.0.0.1 - - [21/Jul/2023:09:06:41 +0000] "GET /subjects/BTC_Avro/versions/ HTTP/1.1" 404 62 "-" "curl/7.81.0" 15 (io.confluent.rest-utils.requests)
[2023-07-21 16:06:58,686] INFO 127.0.0.1 - - [21/Jul/2023:09:06:58 +0000] "GET /subjects/ HTTP/1.1" 200 18 "-" "curl/7.81.0" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:07:09,507] INFO 127.0.0.1 - - [21/Jul/2023:09:07:09 +0000] "GET /subjects/BTC_Avro-value/versions/ HTTP/1.1" 200 5 "-" "curl/7.81.0" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:07:36,095] INFO 127.0.0.1 - - [21/Jul/2023:09:07:36 +0000] "GET /subjects/BTC_Avro-value/versions/ HTTP/1.1" 200 5 "-" "curl/7.81.0" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:11:10,351] INFO 127.0.0.1 - - [21/Jul/2023:09:11:10 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 6 (io.confluent.rest-utils.requests)
[2023-07-21 16:11:55,372] INFO 127.0.0.1 - - [21/Jul/2023:09:11:55 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:12:13,388] INFO 127.0.0.1 - - [21/Jul/2023:09:12:13 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:18:51,223] INFO 127.0.0.1 - - [21/Jul/2023:09:18:51 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 16:19:36,241] INFO 127.0.0.1 - - [21/Jul/2023:09:19:36 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:20:21,263] INFO 127.0.0.1 - - [21/Jul/2023:09:20:21 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:20:51,280] INFO 127.0.0.1 - - [21/Jul/2023:09:20:51 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:32:16,540] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 16:41:04,224] INFO 127.0.0.1 - - [21/Jul/2023:09:41:04 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 6 (io.confluent.rest-utils.requests)
[2023-07-21 16:48:38,345] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 16:50:30,588] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 16:50:42,435] INFO 127.0.0.1 - - [21/Jul/2023:09:50:42 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 16:51:27,456] INFO 127.0.0.1 - - [21/Jul/2023:09:51:27 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:51:33,327] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 16:51:33,340] INFO 127.0.0.1 - - [21/Jul/2023:09:51:33 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 26 (io.confluent.rest-utils.requests)
[2023-07-21 16:51:57,474] INFO 127.0.0.1 - - [21/Jul/2023:09:51:57 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 16:52:01,821] INFO Wait to catch up until the offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 16:52:01,821] INFO Reached offset at 15 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 16:52:01,831] INFO Wait to catch up until the offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 16:52:01,834] INFO Reached offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 16:52:01,836] INFO 127.0.0.1 - - [21/Jul/2023:09:52:01 +0000] "PUT /config HTTP/1.1" 200 28 "-" "curl/7.81.0" 34 (io.confluent.rest-utils.requests)
[2023-07-21 16:52:27,491] INFO 127.0.0.1 - - [21/Jul/2023:09:52:27 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 17:12:27,992] INFO 127.0.0.1 - - [21/Jul/2023:10:12:27 +0000] "GET /subjects HTTP/1.1" 200 18 "-" "Java/11.0.19" 44 (io.confluent.rest-utils.requests)
[2023-07-21 17:14:22,083] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:150)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 17:14:22,085] INFO 127.0.0.1 - - [21/Jul/2023:10:14:22 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 404 63 "-" "Java/11.0.19" 13 (io.confluent.rest-utils.requests)
[2023-07-21 17:14:22,128] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.rest.exceptions.RestNotFoundException: Subject 'BTC-value' not found.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.subjectNotFoundException(Errors.java:78)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.getSchemaByVersion(SubjectVersionsResource.java:150)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:219)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 17:14:22,130] INFO 127.0.0.1 - - [21/Jul/2023:10:14:22 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 404 63 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 17:14:22,134] INFO Registering new schema: subject BTC-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 17:14:22,135] INFO Wait to catch up until the offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 17:14:22,136] INFO Reached offset at 16 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 17:14:22,168] INFO Wait to catch up until the offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 17:14:22,169] INFO Reached offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 17:14:22,170] INFO 127.0.0.1 - - [21/Jul/2023:10:14:22 +0000] "POST /subjects/BTC-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 38 (io.confluent.rest-utils.requests)
[2023-07-21 17:14:39,185] INFO 127.0.0.1 - - [21/Jul/2023:10:14:39 +0000] "GET /subjects HTTP/1.1" 200 30 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 18:16:23,573] INFO 127.0.0.1 - - [21/Jul/2023:11:16:23 +0000] "GET /subjects HTTP/1.1" 200 30 "-" "Java/11.0.19" 60 (io.confluent.rest-utils.requests)
[2023-07-21 18:17:08,593] INFO 127.0.0.1 - - [21/Jul/2023:11:17:08 +0000] "GET /subjects HTTP/1.1" 200 30 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 19:46:25,910] INFO 127.0.0.1 - - [21/Jul/2023:12:46:25 +0000] "GET /subjects HTTP/1.1" 200 30 "-" "Java/11.0.19" 58 (io.confluent.rest-utils.requests)
[2023-07-21 20:30:51,914] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 20:30:51,933] INFO 127.0.0.1 - - [21/Jul/2023:13:30:51 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 59 (io.confluent.rest-utils.requests)
[2023-07-21 20:31:14,886] INFO 127.0.0.1 - - [21/Jul/2023:13:31:14 +0000] "GET /subjects HTTP/1.1" 200 30 "-" "Java/11.0.19" 21 (io.confluent.rest-utils.requests)
[2023-07-21 20:32:47,021] INFO Registering new schema: subject TARGET_AVRO-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 20:32:47,022] INFO Wait to catch up until the offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 20:32:47,022] INFO Reached offset at 17 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 20:32:47,033] INFO Wait to catch up until the offset at 18 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 20:32:47,037] INFO Reached offset at 18 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 20:32:47,039] INFO 127.0.0.1 - - [21/Jul/2023:13:32:47 +0000] "POST /subjects/TARGET_AVRO-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 20 (io.confluent.rest-utils.requests)
[2023-07-21 20:32:57,580] INFO 127.0.0.1 - - [21/Jul/2023:13:32:57 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 20:51:18,380] INFO 127.0.0.1 - - [21/Jul/2023:13:51:18 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 20:53:19,871] INFO 127.0.0.1 - - [21/Jul/2023:13:53:19 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 22:06:29,861] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:06:29,875] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 22:06:29,876] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:06:29,889] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=10, memberId='sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:06:29,897] ERROR Found duplicate URLs for schema registry group members. This indicates a misconfiguration and is common when executing in containers. Use the host.name configuration to set each instance's advertised host name to a value that is routable from all other schema registry instances. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:06:29,926] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=10, memberId='sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:06:29,928] INFO Finished rebalance with leader election result: Assignment{version=1, error=1, leader='sr-1-51513a6a-4a2b-460a-8062-8fe46c9b8f7b', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 22:06:29,930] ERROR Unexpected exception in schema registry group processing thread (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
java.lang.IllegalStateException: The schema registry group contained multiple members advertising the same URL. Verify that each instance has a unique, routable listener by setting the 'listeners' configuration. This error may happen if executing in containers where the default hostname is 'localhost'.
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector.onAssigned(KafkaGroupLeaderElector.java:247)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.onJoinComplete(SchemaRegistryCoordinator.java:149)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.joinGroupIfNeeded(AbstractCoordinator.java:474)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:385)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup(AbstractCoordinator.java:365)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator.poll(SchemaRegistryCoordinator.java:113)
	at io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector$1.run(KafkaGroupLeaderElector.java:199)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-21 22:07:39,173] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:42,178] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:45,183] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:48,188] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:51,194] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:54,199] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:07:57,204] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:00,210] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:03,215] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:06,220] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:09,225] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:12,230] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:15,237] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:18,244] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:21,252] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:24,260] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:27,266] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:30,272] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:33,278] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:36,283] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:39,290] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:42,298] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:45,304] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:45,538] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 22:08:48,312] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:51,321] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:54,329] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:08:57,337] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:00,344] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:03,352] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:06,358] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:09,365] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:12,372] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:15,380] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:18,387] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:21,394] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:24,401] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:27,407] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:30,414] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:33,421] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:36,428] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:39,435] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:42,441] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:45,449] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:48,456] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:51,463] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:54,469] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:09:57,477] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:00,483] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:03,489] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:06,496] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:09,504] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:12,510] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:15,518] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:18,527] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:21,535] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:24,544] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:27,552] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:30,561] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:33,570] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:36,577] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:39,584] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:42,591] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:45,599] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:48,606] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:51,614] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:54,622] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:10:57,630] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:00,638] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:03,646] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:06,654] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:09,662] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:12,670] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:15,679] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:18,687] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:21,695] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:24,704] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:27,712] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: group is already rebalancing (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:29,918] WARN [Schema registry clientId=sr-1, groupId=schema-registry] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:29,919] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-5aa3ffb2-5183-4125-ab74-9910db5e6391 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:29,922] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:11:29,922] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:15:52,819] INFO 127.0.0.1 - - [21/Jul/2023:15:15:52 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 60 (io.confluent.rest-utils.requests)
[2023-07-21 22:20:46,035] INFO 127.0.0.1 - - [21/Jul/2023:15:20:46 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 20 (io.confluent.rest-utils.requests)
[2023-07-21 22:30:51,393] INFO 127.0.0.1 - - [21/Jul/2023:15:30:51 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 200 387 "-" "Java/11.0.19" 49 (io.confluent.rest-utils.requests)
[2023-07-21 22:30:51,446] INFO 127.0.0.1 - - [21/Jul/2023:15:30:51 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 23 (io.confluent.rest-utils.requests)
[2023-07-21 22:30:51,484] INFO 127.0.0.1 - - [21/Jul/2023:15:30:51 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 200 387 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 22:33:26,704] INFO 127.0.0.1 - - [21/Jul/2023:15:33:26 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 200 387 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 22:34:22,717] INFO 127.0.0.1 - - [21/Jul/2023:15:34:22 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 200 387 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-21 22:34:22,761] INFO 127.0.0.1 - - [21/Jul/2023:15:34:22 +0000] "GET /subjects/BTC-value/versions/latest HTTP/1.1" 200 387 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 22:40:26,376] INFO Registering new schema: subject QUERYABLE_TABLE_AVRO-value, version null, id null, type null, schema size 229 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 22:40:26,384] ERROR Request Failed with exception  (io.confluent.rest.exceptions.DebuggableExceptionMapper)
io.confluent.kafka.schemaregistry.rest.exceptions.RestUnknownLeaderException: Leader not known.
	at io.confluent.kafka.schemaregistry.rest.exceptions.Errors.unknownLeaderException(Errors.java:184)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:428)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:52)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:134)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:177)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$VoidOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:159)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.ServletContainer.serviceImpl(ServletContainer.java:378)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:553)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:494)
	at org.glassfish.jersey.servlet.ServletContainer.doFilter(ServletContainer.java:431)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: io.confluent.kafka.schemaregistry.exceptions.UnknownLeaderException: Register schema request failed since leader is unknown
	at io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry.registerOrForward(KafkaSchemaRegistry.java:768)
	at io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource.register(SubjectVersionsResource.java:406)
	... 59 more
[2023-07-21 22:40:26,386] INFO 127.0.0.1 - - [21/Jul/2023:15:40:26 +0000] "POST /subjects/QUERYABLE_TABLE_AVRO-value/versions?normalize=false HTTP/1.1" 500 50 "-" "Java/11.0.19" 15 (io.confluent.rest-utils.requests)
[2023-07-21 22:51:20,174] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 22:51:20,175] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-21 22:51:20,184] INFO Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 22:51:20,217] INFO Stopped o.e.j.s.ServletContextHandler@68fe48d7{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 22:51:20,224] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:51:20,226] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:51:20,227] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:51:20,227] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:51:20,234] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:51:20,238] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:51:20,238] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:51:20,238] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-21 22:51:20,240] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-21 22:51:20,240] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-21 22:51:20,243] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 22:51:20,245] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-21 22:51:20,247] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:51:20,248] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:51:20,248] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:01,365] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-21 22:55:01,408] INFO Logging initialized @575ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-21 22:55:01,431] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-21 22:55:01,525] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-21 22:55:01,725] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:01,726] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:02,201] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:02,201] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:02,201] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:02,221] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,346] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-21 22:55:02,351] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-21 22:55:02,371] INFO Validating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,377] WARN The replication factor of the schema topic _schemas is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,434] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:55:02,484] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:55:02,484] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:55:02,486] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-21 22:55:02,583] INFO Wait to catch up until the offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,664] INFO Reached offset at 20 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,674] INFO Validating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 22:55:02,675] WARN The replication factor of the topic _schema_encoders is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-21 22:55:02,698] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 22:55:02,699] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-21 22:55:02,699] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-21 22:55:02,706] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 22:55:02,707] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 22:55:02,708] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-21 22:55:02,708] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-21 22:55:02,724] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,725] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,732] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-29e760f0-8434-4e1b-9997-1872a7af1ad6 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,733] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,733] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,735] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=1, memberId='sr-1-29e760f0-8434-4e1b-9997-1872a7af1ad6', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,742] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=1, memberId='sr-1-29e760f0-8434-4e1b-9997-1872a7af1ad6', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-21 22:55:02,743] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-29e760f0-8434-4e1b-9997-1872a7af1ad6', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-21 22:55:02,757] INFO Wait to catch up until the offset at 21 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:02,758] INFO Reached offset at 21 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-21 22:55:03,213] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-21 22:55:03,213] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-21 22:55:03,249] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-21 22:55:03,340] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-21 22:55:03,376] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-21 22:55:03,376] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-21 22:55:03,377] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-21 22:55:03,730] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-21 22:55:03,933] INFO Started o.e.j.s.ServletContextHandler@68fe48d7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 22:55:03,944] INFO Started o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-21 22:55:03,960] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-21 22:55:03,961] INFO Started @3130ms (org.eclipse.jetty.server.Server)
[2023-07-21 22:55:03,962] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 22:55:03,963] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-21 23:22:05,294] INFO 127.0.0.1 - - [21/Jul/2023:16:22:04 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 370 (io.confluent.rest-utils.requests)
[2023-07-21 23:25:52,566] INFO 127.0.0.1 - - [21/Jul/2023:16:25:52 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 11 (io.confluent.rest-utils.requests)
[2023-07-21 23:26:49,673] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 23:26:49,759] INFO 127.0.0.1 - - [21/Jul/2023:16:26:49 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 157 (io.confluent.rest-utils.requests)
[2023-07-21 23:26:50,164] INFO Registering new schema: subject BTC_Avro-value, version null, id null, type null, schema size 291 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-21 23:26:50,170] INFO 127.0.0.1 - - [21/Jul/2023:16:26:50 +0000] "POST /subjects/BTC_Avro-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 8 (io.confluent.rest-utils.requests)
[2023-07-21 23:27:39,330] INFO 127.0.0.1 - - [21/Jul/2023:16:27:39 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 15 (io.confluent.rest-utils.requests)
[2023-07-21 23:27:39,375] INFO 127.0.0.1 - - [21/Jul/2023:16:27:39 +0000] "POST /subjects/BTC_Avro-value?normalize=false&deleted=true HTTP/1.1" 200 392 "-" "Java/11.0.19" 8 (io.confluent.rest-utils.requests)
[2023-07-21 23:27:39,621] INFO 127.0.0.1 - - [21/Jul/2023:16:27:39 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-21 23:28:31,275] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 23:28:32,059] INFO 127.0.0.1 - - [21/Jul/2023:16:28:32 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-21 23:36:02,513] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 23:36:03,826] INFO 127.0.0.1 - - [21/Jul/2023:16:36:03 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 64 (io.confluent.rest-utils.requests)
[2023-07-21 23:40:20,762] INFO 127.0.0.1 - - [21/Jul/2023:16:40:20 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 9 (io.confluent.rest-utils.requests)
[2023-07-21 23:40:21,365] INFO 127.0.0.1 - - [21/Jul/2023:16:40:20 +0000] "POST /subjects/BTC_Avro-value?normalize=false&deleted=true HTTP/1.1" 200 392 "-" "Java/11.0.19" 418 (io.confluent.rest-utils.requests)
[2023-07-21 23:41:02,459] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 23:41:03,353] INFO 127.0.0.1 - - [21/Jul/2023:16:41:03 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-21 23:42:37,776] INFO 127.0.0.1 - - [21/Jul/2023:16:42:37 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-21 23:42:37,992] INFO 127.0.0.1 - - [21/Jul/2023:16:42:37 +0000] "POST /subjects/BTC_Avro-value?normalize=false&deleted=true HTTP/1.1" 200 392 "-" "Java/11.0.19" 9 (io.confluent.rest-utils.requests)
[2023-07-21 23:45:55,032] INFO 127.0.0.1 - - [21/Jul/2023:16:45:54 +0000] "GET /subjects HTTP/1.1" 200 50 "-" "Java/11.0.19" 152 (io.confluent.rest-utils.requests)
[2023-07-21 23:46:10,946] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 23:46:17,474] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-21 23:46:18,178] ERROR Unknown error when running consumer:  (kafka.tools.ConsoleConsumer$)
org.apache.kafka.common.errors.SerializationException: Unknown magic byte!
	at io.confluent.kafka.serializers.AbstractKafkaSchemaSerDe.getByteBuffer(AbstractKafkaSchemaSerDe.java:539)
	at io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer$DeserializationContext.<init>(AbstractKafkaAvroDeserializer.java:386)
	at io.confluent.kafka.serializers.AbstractKafkaAvroDeserializer.deserialize(AbstractKafkaAvroDeserializer.java:184)
	at io.confluent.kafka.formatter.AvroMessageFormatter$AvroMessageDeserializer.deserialize(AvroMessageFormatter.java:134)
	at io.confluent.kafka.formatter.AvroMessageFormatter.writeTo(AvroMessageFormatter.java:89)
	at io.confluent.kafka.formatter.SchemaMessageFormatter.writeTo(SchemaMessageFormatter.java:262)
	at kafka.tools.ConsoleConsumer$.process(ConsoleConsumer.scala:116)
	at kafka.tools.ConsoleConsumer$.run(ConsoleConsumer.scala:76)
	at kafka.tools.ConsoleConsumer$.main(ConsoleConsumer.scala:53)
	at kafka.tools.ConsoleConsumer.main(ConsoleConsumer.scala)
[2023-07-21 23:55:22,772] INFO 127.0.0.1 - - [21/Jul/2023:16:55:22 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=BTC_Avro-value HTTP/1.1" 200 346 "-" "Java/11.0.19" 11 (io.confluent.rest-utils.requests)
[2023-07-22 00:17:34,038] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-22 00:17:34,043] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-22 00:17:34,092] INFO Stopped o.e.j.s.ServletContextHandler@5a82ebf8{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 00:17:34,174] INFO Stopped o.e.j.s.ServletContextHandler@68fe48d7{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 00:17:34,191] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 00:17:34,199] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 00:17:34,205] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 00:17:34,205] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 00:17:34,231] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 00:17:34,237] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 00:17:34,238] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 00:17:34,240] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-22 00:17:34,329] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-22 00:17:34,330] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-22 00:17:34,342] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-22 00:17:34,344] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 00:17:34,345] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-22 00:17:34,347] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 00:17:34,348] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:10,678] INFO SchemaRegistryConfig values: 
	access.control.allow.headers = 
	access.control.allow.methods = 
	access.control.allow.origin = 
	access.control.skip.options = true
	authentication.method = NONE
	authentication.realm = 
	authentication.roles = [*]
	authentication.skip.paths = []
	avro.compatibility.level = 
	compression.enable = true
	connector.connection.limit = 0
	csrf.prevention.enable = false
	csrf.prevention.token.endpoint = /csrf
	csrf.prevention.token.expiration.minutes = 30
	csrf.prevention.token.max.entries = 10000
	debug = false
	dos.filter.delay.ms = 100
	dos.filter.enabled = false
	dos.filter.insert.headers = true
	dos.filter.ip.whitelist = []
	dos.filter.managed.attr = false
	dos.filter.max.idle.tracker.ms = 30000
	dos.filter.max.requests.ms = 30000
	dos.filter.max.requests.per.connection.per.sec = 25
	dos.filter.max.requests.per.sec = 25
	dos.filter.max.wait.ms = 50
	dos.filter.throttle.ms = 30000
	dos.filter.throttled.requests = 5
	host.name = TranMinhPhuong.
	http2.enabled = true
	idle.timeout.ms = 30000
	inter.instance.headers.whitelist = []
	inter.instance.listener.name = 
	inter.instance.protocol = http
	kafkagroup.heartbeat.interval.ms = 3000
	kafkagroup.rebalance.timeout.ms = 300000
	kafkagroup.session.timeout.ms = 10000
	kafkastore.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkastore.checkpoint.dir = /tmp
	kafkastore.checkpoint.version = 0
	kafkastore.connection.url = 
	kafkastore.group.id = 
	kafkastore.init.timeout.ms = 60000
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	kafkastore.sasl.kerberos.service.name = 
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.security.protocol = PLAINTEXT
	kafkastore.ssl.cipher.suites = 
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.key.password = [hidden]
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.ssl.keystore.location = 
	kafkastore.ssl.keystore.password = [hidden]
	kafkastore.ssl.keystore.type = JKS
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.trustmanager.algorithm = PKIX
	kafkastore.ssl.truststore.location = 
	kafkastore.ssl.truststore.password = [hidden]
	kafkastore.ssl.truststore.type = JKS
	kafkastore.timeout.ms = 500
	kafkastore.topic = _schemas
	kafkastore.topic.replication.factor = 3
	kafkastore.topic.skip.validation = false
	kafkastore.update.handlers = []
	kafkastore.write.max.retries = 5
	leader.connect.timeout.ms = 60000
	leader.election.delay = false
	leader.eligibility = true
	leader.read.timeout.ms = 60000
	listener.protocol.map = []
	listeners = [http://localhost:8081]
	master.eligibility = null
	metadata.encoder.old.secret = null
	metadata.encoder.secret = [hidden]
	metadata.encoder.topic = _schema_encoders
	metric.reporters = []
	metrics.jmx.prefix = kafka.schema.registry
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	metrics.tag.map = []
	mode.mutability = true
	nosniff.prevention.enable = false
	port = 8081
	proxy.protocol.enabled = false
	reject.options.request = false
	request.logger.name = io.confluent.rest-utils.requests
	request.queue.capacity = 2147483647
	request.queue.capacity.growby = 64
	request.queue.capacity.init = 128
	resource.extension.class = []
	resource.extension.classes = []
	resource.static.locations = []
	response.http.headers.config = 
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	rest.servlet.initializor.classes = []
	schema.cache.expiry.secs = 300
	schema.cache.size = 1000
	schema.canonicalize.on.consume = []
	schema.compatibility.level = backward
	schema.providers = []
	schema.registry.group.id = schema-registry
	schema.registry.inter.instance.protocol = 
	schema.registry.resource.extension.class = []
	server.connection.limit = 0
	shutdown.graceful.ms = 1000
	ssl.cipher.suites = []
	ssl.client.auth = false
	ssl.client.authentication = NONE
	ssl.enabled.protocols = []
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = [hidden]
	ssl.keymanager.algorithm = 
	ssl.keystore.location = 
	ssl.keystore.password = [hidden]
	ssl.keystore.reload = false
	ssl.keystore.type = JKS
	ssl.keystore.watch.location = 
	ssl.protocol = TLS
	ssl.provider = 
	ssl.trustmanager.algorithm = 
	ssl.truststore.location = 
	ssl.truststore.password = [hidden]
	ssl.truststore.type = JKS
	suppress.stack.trace.response = true
	thread.pool.max = 200
	thread.pool.min = 8
	websocket.path.prefix = /ws
	websocket.servlet.initializor.classes = []
 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryConfig)
[2023-07-22 20:57:10,736] INFO Logging initialized @873ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2023-07-22 20:57:10,758] INFO Initial capacity 128, increased by 64, maximum capacity 2147483647. (io.confluent.rest.ApplicationServer)
[2023-07-22 20:57:10,876] INFO Adding listener with HTTP/2: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.rest.ApplicationServer)
[2023-07-22 20:57:11,141] INFO Found internal listener: NamedURI{uri=http://localhost:8081, name='null'} (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:11,142] INFO Setting my identity to version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:11,713] INFO Registering schema provider for AVRO: io.confluent.kafka.schemaregistry.avro.AvroSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:11,713] INFO Registering schema provider for JSON: io.confluent.kafka.schemaregistry.json.JsonSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:11,713] INFO Registering schema provider for PROTOBUF: io.confluent.kafka.schemaregistry.protobuf.ProtobufSchemaProvider (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:11,735] INFO Initializing KafkaStore with broker endpoints: PLAINTEXT://localhost:9092 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:11,880] INFO KafkaCacheConfig values: 
	kafkacache.backing.cache = memory
	kafkacache.bootstrap.servers = [PLAINTEXT://localhost:9092]
	kafkacache.bounded.cache.expiry.secs = -1
	kafkacache.bounded.cache.size = -1
	kafkacache.checkpoint.dir = /tmp
	kafkacache.checkpoint.version = 0
	kafkacache.client.id = null
	kafkacache.data.dir = /tmp
	kafkacache.group.id = kafka-cache-TranMinhPhuong.
	kafkacache.init.timeout.ms = 300000
	kafkacache.poll.timeout.ms = 9223372036854775807
	kafkacache.sasl.jaas.config = null
	kafkacache.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	kafkacache.sasl.kerberos.min.time.before.relogin = 60000
	kafkacache.sasl.kerberos.service.name = 
	kafkacache.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkacache.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkacache.sasl.mechanism = GSSAPI
	kafkacache.security.protocol = PLAINTEXT
	kafkacache.ssl.cipher.suites = 
	kafkacache.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkacache.ssl.endpoint.identification.algorithm = 
	kafkacache.ssl.key.password = [hidden]
	kafkacache.ssl.keymanager.algorithm = SunX509
	kafkacache.ssl.keystore.location = 
	kafkacache.ssl.keystore.password = [hidden]
	kafkacache.ssl.keystore.type = JKS
	kafkacache.ssl.protocol = TLS
	kafkacache.ssl.provider = 
	kafkacache.ssl.trustmanager.algorithm = PKIX
	kafkacache.ssl.truststore.location = 
	kafkacache.ssl.truststore.password = [hidden]
	kafkacache.ssl.truststore.type = JKS
	kafkacache.timeout.ms = 60000
	kafkacache.topic = _schema_encoders
	kafkacache.topic.num.partitions = 1
	kafkacache.topic.partitions = []
	kafkacache.topic.partitions.offset = beginning
	kafkacache.topic.read.only = false
	kafkacache.topic.replication.factor = 3
	kafkacache.topic.require.compact = true
	kafkacache.topic.skip.validation = false
 (io.kcache.KafkaCacheConfig)
[2023-07-22 20:57:11,887] INFO Initializing Kafka cache kafka-cache-reader-_schema_encoders with broker endpoints PLAINTEXT://localhost:9092 (io.kcache.KafkaCache)
[2023-07-22 20:57:11,905] INFO Creating schemas topic _schemas (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:11,906] WARN Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:12,098] INFO Kafka store reader thread starting consumer (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 20:57:12,139] INFO Seeking to beginning for all partitions (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 20:57:12,140] INFO Initialized last consumed offset to -1 (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 20:57:12,143] INFO [kafka-store-reader-thread-_schemas]: Starting (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 20:57:12,239] INFO Wait to catch up until the offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:12,279] INFO Reached offset at 0 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:12,289] INFO Creating topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 20:57:12,290] WARN Creating the topic _schema_encoders using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic. (io.kcache.KafkaCache)
[2023-07-22 20:57:12,351] INFO Seeking to start for all partitions for topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 20:57:12,353] INFO Initialized last read offsets to {0=-1} (io.kcache.KafkaCache)
[2023-07-22 20:57:12,353] INFO KafkaTopicReader thread started for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-22 20:57:12,360] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-22 20:57:12,362] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 20:57:12,362] INFO Joining schema registry with Kafka-based coordination (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 20:57:12,362] INFO Starting (io.kcache.utils.ShutdownableThread)
[2023-07-22 20:57:12,381] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,384] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,393] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-4a8ad623-326a-4334-85ce-756604e9bafd (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,394] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,394] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,397] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=1, memberId='sr-1-4a8ad623-326a-4334-85ce-756604e9bafd', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,407] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=1, memberId='sr-1-4a8ad623-326a-4334-85ce-756604e9bafd', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 20:57:12,409] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-4a8ad623-326a-4334-85ce-756604e9bafd', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-22 20:57:12,429] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:12,431] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 20:57:12,871] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-22 20:57:12,871] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 20:57:12,925] INFO Binding SchemaRegistryRestApplication to all listeners. (io.confluent.rest.Application)
[2023-07-22 20:57:13,067] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.19+7-post-Ubuntu-0ubuntu122.04.1 (org.eclipse.jetty.server.Server)
[2023-07-22 20:57:13,107] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2023-07-22 20:57:13,107] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2023-07-22 20:57:13,108] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2023-07-22 20:57:13,534] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version)
[2023-07-22 20:57:13,781] INFO Started o.e.j.s.ServletContextHandler@4eb45fec{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 20:57:13,792] INFO Started o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 20:57:13,809] INFO Started NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-22 20:57:13,811] INFO Started @3949ms (org.eclipse.jetty.server.Server)
[2023-07-22 20:57:13,812] INFO Schema Registry version: 7.4.0 commitId: 3870d17aa92a8da9bc9272a2ed9ac1678bb58ce6 (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-22 20:57:13,812] INFO Server started, listening for requests... (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
[2023-07-22 21:12:25,777] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 957 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:12:25,862] INFO Wait to catch up until the offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:12:25,862] INFO Reached offset at 1 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:12:25,889] INFO Wait to catch up until the offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:12:25,909] INFO Reached offset at 2 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:12:25,946] INFO 127.0.0.1 - - [22/Jul/2023:14:12:25 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 483 (io.confluent.rest-utils.requests)
[2023-07-22 21:12:26,580] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 957 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:12:26,586] INFO 127.0.0.1 - - [22/Jul/2023:14:12:26 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 9 (io.confluent.rest-utils.requests)
[2023-07-22 21:12:38,699] INFO 127.0.0.1 - - [22/Jul/2023:14:12:38 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 14 (io.confluent.rest-utils.requests)
[2023-07-22 21:12:38,764] INFO 127.0.0.1 - - [22/Jul/2023:14:12:38 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 21 (io.confluent.rest-utils.requests)
[2023-07-22 21:12:39,142] INFO 127.0.0.1 - - [22/Jul/2023:14:12:39 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 50 (io.confluent.rest-utils.requests)
[2023-07-22 21:18:30,995] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,037] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,056] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,227] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Attempt to heartbeat with Generation{generationId=1, memberId='sr-1-4a8ad623-326a-4334-85ce-756604e9bafd', protocol='v0'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,228] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,228] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,229] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-22 21:18:31,229] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,245] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-4bc715ae-dbd9-430f-9de3-10534cf8d63e (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,246] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,247] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,308] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=3, memberId='sr-1-4bc715ae-dbd9-430f-9de3-10534cf8d63e', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,520] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=3, memberId='sr-1-4bc715ae-dbd9-430f-9de3-10534cf8d63e', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 21:18:31,522] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-4bc715ae-dbd9-430f-9de3-10534cf8d63e', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-22 21:18:31,593] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:18:31,597] INFO Reached offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:18:32,078] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-22 21:18:32,079] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 21:29:28,779] INFO KafkaAvroDeserializerConfig values: 
	auto.register.schemas = true
	avro.reflection.allow.null = false
	avro.use.logical.type.converters = false
	basic.auth.credentials.source = URL
	basic.auth.user.info = [hidden]
	bearer.auth.cache.expiry.buffer.seconds = 300
	bearer.auth.client.id = null
	bearer.auth.client.secret = null
	bearer.auth.credentials.source = STATIC_TOKEN
	bearer.auth.identity.pool.id = null
	bearer.auth.issuer.endpoint.url = null
	bearer.auth.logical.cluster = null
	bearer.auth.scope = null
	bearer.auth.scope.claim.name = scope
	bearer.auth.sub.claim.name = sub
	bearer.auth.token = [hidden]
	context.name.strategy = class io.confluent.kafka.serializers.context.NullContextNameStrategy
	id.compatibility.strict = true
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	latest.cache.size = 1000
	latest.cache.ttl.sec = -1
	latest.compatibility.strict = true
	max.schemas.per.subject = 1000
	normalize.schemas = false
	proxy.host = 
	proxy.port = -1
	rule.actions = []
	rule.executors = []
	schema.format = null
	schema.reflection = false
	schema.registry.basic.auth.user.info = [hidden]
	schema.registry.ssl.cipher.suites = null
	schema.registry.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	schema.registry.ssl.endpoint.identification.algorithm = https
	schema.registry.ssl.engine.factory.class = null
	schema.registry.ssl.key.password = null
	schema.registry.ssl.keymanager.algorithm = SunX509
	schema.registry.ssl.keystore.certificate.chain = null
	schema.registry.ssl.keystore.key = null
	schema.registry.ssl.keystore.location = null
	schema.registry.ssl.keystore.password = null
	schema.registry.ssl.keystore.type = JKS
	schema.registry.ssl.protocol = TLSv1.3
	schema.registry.ssl.provider = null
	schema.registry.ssl.secure.random.implementation = null
	schema.registry.ssl.trustmanager.algorithm = PKIX
	schema.registry.ssl.truststore.certificates = null
	schema.registry.ssl.truststore.location = null
	schema.registry.ssl.truststore.password = null
	schema.registry.ssl.truststore.type = JKS
	schema.registry.url = [http://localhost:8081]
	specific.avro.key.type = null
	specific.avro.reader = false
	specific.avro.value.type = null
	use.latest.version = false
	use.latest.with.metadata = null
	use.schema.id = -1
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
 (io.confluent.kafka.serializers.KafkaAvroDeserializerConfig)
[2023-07-22 21:29:29,635] INFO 127.0.0.1 - - [22/Jul/2023:14:29:29 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 8 (io.confluent.rest-utils.requests)
[2023-07-22 21:35:11,892] INFO 127.0.0.1 - - [22/Jul/2023:14:35:11 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 6 (io.confluent.rest-utils.requests)
[2023-07-22 21:35:12,065] INFO 127.0.0.1 - - [22/Jul/2023:14:35:12 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 18 (io.confluent.rest-utils.requests)
[2023-07-22 21:40:22,654] INFO 127.0.0.1 - - [22/Jul/2023:14:40:22 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 52 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:43,723] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:45:43,725] INFO Wait to catch up until the offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:45:43,726] INFO Reached offset at 3 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:45:43,744] INFO Wait to catch up until the offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:45:43,747] INFO Reached offset at 4 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 21:45:43,749] INFO 127.0.0.1 - - [22/Jul/2023:14:45:43 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 37 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:44,149] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:45:44,152] INFO 127.0.0.1 - - [22/Jul/2023:14:45:44 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:57,480] INFO 127.0.0.1 - - [22/Jul/2023:14:45:57 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:57,489] INFO 127.0.0.1 - - [22/Jul/2023:14:45:57 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:57,591] INFO 127.0.0.1 - - [22/Jul/2023:14:45:57 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:57,609] INFO 127.0.0.1 - - [22/Jul/2023:14:45:57 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 11 (io.confluent.rest-utils.requests)
[2023-07-22 21:45:57,924] INFO 127.0.0.1 - - [22/Jul/2023:14:45:57 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:46:39,651] INFO 127.0.0.1 - - [22/Jul/2023:14:46:39 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:46:39,837] INFO 127.0.0.1 - - [22/Jul/2023:14:46:39 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-22 21:46:39,903] INFO 127.0.0.1 - - [22/Jul/2023:14:46:39 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 21:46:39,915] INFO 127.0.0.1 - - [22/Jul/2023:14:46:39 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 9 (io.confluent.rest-utils.requests)
[2023-07-22 21:52:12,803] INFO 127.0.0.1 - - [22/Jul/2023:14:52:12 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:13,476] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:53:13,480] INFO 127.0.0.1 - - [22/Jul/2023:14:53:13 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 7 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:13,888] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 21:53:13,890] INFO 127.0.0.1 - - [22/Jul/2023:14:53:13 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:24,805] INFO 127.0.0.1 - - [22/Jul/2023:14:53:24 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:24,816] INFO 127.0.0.1 - - [22/Jul/2023:14:53:24 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 6 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:24,879] INFO 127.0.0.1 - - [22/Jul/2023:14:53:24 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:24,887] INFO 127.0.0.1 - - [22/Jul/2023:14:53:24 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 21:53:25,174] INFO 127.0.0.1 - - [22/Jul/2023:14:53:25 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 21:57:37,550] INFO 127.0.0.1 - - [22/Jul/2023:14:57:37 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 10 (io.confluent.rest-utils.requests)
[2023-07-22 21:58:22,571] INFO 127.0.0.1 - - [22/Jul/2023:14:58:22 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:20,888] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 22:02:20,893] INFO 127.0.0.1 - - [22/Jul/2023:15:02:20 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 8 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:21,282] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 22:02:21,284] INFO 127.0.0.1 - - [22/Jul/2023:15:02:21 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:33,931] INFO 127.0.0.1 - - [22/Jul/2023:15:02:33 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:33,939] INFO 127.0.0.1 - - [22/Jul/2023:15:02:33 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:33,986] INFO 127.0.0.1 - - [22/Jul/2023:15:02:33 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:34,009] INFO 127.0.0.1 - - [22/Jul/2023:15:02:33 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 13 (io.confluent.rest-utils.requests)
[2023-07-22 22:02:34,318] INFO 127.0.0.1 - - [22/Jul/2023:15:02:34 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 22:03:22,531] INFO 127.0.0.1 - - [22/Jul/2023:15:03:22 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 5 (io.confluent.rest-utils.requests)
[2023-07-22 22:03:22,712] INFO 127.0.0.1 - - [22/Jul/2023:15:03:22 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:03:22,773] INFO 127.0.0.1 - - [22/Jul/2023:15:03:22 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 3 (io.confluent.rest-utils.requests)
[2023-07-22 22:03:22,779] INFO 127.0.0.1 - - [22/Jul/2023:15:03:22 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:05:06,769] INFO 127.0.0.1 - - [22/Jul/2023:15:05:06 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:05:06,962] INFO 127.0.0.1 - - [22/Jul/2023:15:05:06 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:05:07,028] INFO 127.0.0.1 - - [22/Jul/2023:15:05:07 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 2 (io.confluent.rest-utils.requests)
[2023-07-22 22:05:07,034] INFO 127.0.0.1 - - [22/Jul/2023:15:05:07 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 4 (io.confluent.rest-utils.requests)
[2023-07-22 22:09:44,994] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response. isDisconnected: false. Rediscovery will be attempted. (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,414] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,464] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,738] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Attempt to heartbeat with Generation{generationId=3, memberId='sr-1-4bc715ae-dbd9-430f-9de3-10534cf8d63e', protocol='v0'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,768] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,769] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,771] INFO Rebalance started (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-22 22:09:45,773] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,915] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: need to re-join with the given member-id: sr-1-7a4497cb-5ef3-4bd7-ad2f-0d584ba6b844 (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,920] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,921] INFO [Schema registry clientId=sr-1, groupId=schema-registry] (Re-)joining group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:45,956] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully joined group with generation Generation{generationId=5, memberId='sr-1-7a4497cb-5ef3-4bd7-ad2f-0d584ba6b844', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:46,086] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Successfully synced group in generation Generation{generationId=5, memberId='sr-1-7a4497cb-5ef3-4bd7-ad2f-0d584ba6b844', protocol='v0'} (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:09:46,096] INFO Finished rebalance with leader election result: Assignment{version=1, error=0, leader='sr-1-7a4497cb-5ef3-4bd7-ad2f-0d584ba6b844', leaderIdentity=version=1,host=TranMinhPhuong.,port=8081,scheme=http,leaderEligibility=true} (io.confluent.kafka.schemaregistry.leaderelector.kafka.KafkaGroupLeaderElector)
[2023-07-22 22:09:46,254] INFO Wait to catch up until the offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 22:09:46,271] INFO Reached offset at 5 (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 22:09:46,791] INFO Reading to end of offsets {_schema_encoders-0=0} (io.kcache.KafkaCache)
[2023-07-22 22:09:46,791] INFO During init or sync, processed 0 records from topic _schema_encoders (io.kcache.KafkaCache)
[2023-07-22 22:09:55,329] INFO Registering new schema: subject avro_data-value, version null, id null, type null, schema size 1015 (io.confluent.kafka.schemaregistry.rest.resources.SubjectVersionsResource)
[2023-07-22 22:09:55,355] INFO 127.0.0.1 - - [22/Jul/2023:15:09:55 +0000] "POST /subjects/avro_data-value/versions?normalize=false HTTP/1.1" 200 8 "-" "Java/11.0.19" 135 (io.confluent.rest-utils.requests)
[2023-07-22 22:11:01,952] INFO 127.0.0.1 - - [22/Jul/2023:15:11:01 +0000] "GET /schemas/ids/1?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1144 "-" "Java/11.0.19" 90 (io.confluent.rest-utils.requests)
[2023-07-22 22:11:02,053] INFO 127.0.0.1 - - [22/Jul/2023:15:11:02 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1191 "-" "Java/11.0.19" 16 (io.confluent.rest-utils.requests)
[2023-07-22 22:11:02,247] INFO 127.0.0.1 - - [22/Jul/2023:15:11:02 +0000] "GET /schemas/ids/2?fetchMaxId=false&subject=avro_data-value HTTP/1.1" 200 1214 "-" "Java/11.0.19" 8 (io.confluent.rest-utils.requests)
[2023-07-22 22:11:02,269] INFO 127.0.0.1 - - [22/Jul/2023:15:11:02 +0000] "POST /subjects/avro_data-value?normalize=false&deleted=true HTTP/1.1" 200 1261 "-" "Java/11.0.19" 14 (io.confluent.rest-utils.requests)
[2023-07-22 22:11:02,846] INFO 127.0.0.1 - - [22/Jul/2023:15:11:02 +0000] "GET /subjects HTTP/1.1" 200 19 "-" "Java/11.0.19" 30 (io.confluent.rest-utils.requests)
[2023-07-22 22:22:00,442] INFO Stopped NetworkTrafficServerConnector@7283d3eb{HTTP/1.1, (http/1.1, h2c)}{localhost:8081} (org.eclipse.jetty.server.AbstractConnector)
[2023-07-22 22:22:00,450] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session)
[2023-07-22 22:22:00,472] INFO Stopped o.e.j.s.ServletContextHandler@39ad12b6{/ws,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 22:22:00,553] INFO Stopped o.e.j.s.ServletContextHandler@4eb45fec{/,null,STOPPED} (org.eclipse.jetty.server.handler.ContextHandler)
[2023-07-22 22:22:00,569] INFO Shutting down schema registry (io.confluent.kafka.schemaregistry.storage.KafkaSchemaRegistry)
[2023-07-22 22:22:00,575] INFO [kafka-store-reader-thread-_schemas]: Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 22:22:00,578] INFO [kafka-store-reader-thread-_schemas]: Stopped (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 22:22:00,578] INFO [kafka-store-reader-thread-_schemas]: Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 22:22:00,594] INFO KafkaStoreReaderThread shutdown complete. (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread)
[2023-07-22 22:22:00,601] INFO Kafka store producer shut down (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 22:22:00,601] INFO Kafka store shut down complete (io.confluent.kafka.schemaregistry.storage.KafkaStore)
[2023-07-22 22:22:00,602] INFO Shutting down MetadataEncoderService (io.confluent.kafka.schemaregistry.storage.encoder.MetadataEncoderService)
[2023-07-22 22:22:00,604] INFO Stopped (io.kcache.utils.ShutdownableThread)
[2023-07-22 22:22:00,604] INFO Shutdown completed (io.kcache.utils.ShutdownableThread)
[2023-07-22 22:22:00,607] INFO KafkaTopicReader thread shutdown complete for kafka-cache-reader-_schema_encoders. (io.kcache.KafkaCache)
[2023-07-22 22:22:00,639] INFO Kafka cache shut down complete for kafka-cache-reader-_schema_encoders (io.kcache.KafkaCache)
[2023-07-22 22:22:00,644] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Member sr-1-7a4497cb-5ef3-4bd7-ad2f-0d584ba6b844 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:22:00,647] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Resetting generation and member id due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:22:00,647] INFO [Schema registry clientId=sr-1, groupId=schema-registry] Request joining group due to: consumer pro-actively leaving the group (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
[2023-07-22 22:22:00,647] WARN [Schema registry clientId=sr-1, groupId=schema-registry] Close timed out with 1 pending requests to coordinator, terminating client connections (io.confluent.kafka.schemaregistry.leaderelector.kafka.SchemaRegistryCoordinator)
